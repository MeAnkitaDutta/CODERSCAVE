{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":6399975,"sourceType":"datasetVersion","datasetId":3690036}],"dockerImageVersionId":30732,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Import libraries\nimport string\nimport nltk\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom nltk.corpus import stopwords\nfrom nltk.stem import WordNetLemmatizer\nfrom sklearn.feature_extraction.text import TfidfTransformer\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.svm import SVC\nimport warnings\nimport plotly.express as px\nimport string\nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.naive_bayes import GaussianNB\nimport xgboost as xgb\nfrom xgboost import XGBClassifier\nfrom sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, ConfusionMatrixDisplay\nfrom sklearn.model_selection import RandomizedSearchCV, train_test_split\nfrom scipy.stats import randint\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report, mean_squared_error\nfrom sklearn.metrics import roc_curve, roc_auc_score,auc\nfrom sklearn.model_selection import cross_val_predict\nfrom sklearn import metrics\n\nwarnings.simplefilter(action='ignore', category=FutureWarning)","metadata":{"execution":{"iopub.status.busy":"2024-06-16T10:26:43.931124Z","iopub.execute_input":"2024-06-16T10:26:43.932451Z","iopub.status.idle":"2024-06-16T10:26:44.145756Z","shell.execute_reply.started":"2024-06-16T10:26:43.93241Z","shell.execute_reply":"2024-06-16T10:26:44.144704Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"nltk.download('punkt')\nnltk.download('stopwords')\nnltk.download('wordnet')","metadata":{"execution":{"iopub.status.busy":"2024-06-16T10:26:46.462725Z","iopub.execute_input":"2024-06-16T10:26:46.463165Z","iopub.status.idle":"2024-06-16T10:26:46.842192Z","shell.execute_reply.started":"2024-06-16T10:26:46.463132Z","shell.execute_reply":"2024-06-16T10:26:46.840836Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 1. Data Loading and Intial Exploration","metadata":{}},{"cell_type":"code","source":"data_path = \"/kaggle/input/spam-email-dataset/emails.csv\"\ndata = pd.read_csv(data_path)","metadata":{"execution":{"iopub.status.busy":"2024-06-16T10:26:50.20251Z","iopub.execute_input":"2024-06-16T10:26:50.202912Z","iopub.status.idle":"2024-06-16T10:26:50.421499Z","shell.execute_reply.started":"2024-06-16T10:26:50.202885Z","shell.execute_reply":"2024-06-16T10:26:50.420028Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"spam_df = data.copy()\nspam_df.head()","metadata":{"execution":{"iopub.status.busy":"2024-06-16T10:26:55.602427Z","iopub.execute_input":"2024-06-16T10:26:55.60288Z","iopub.status.idle":"2024-06-16T10:26:55.625481Z","shell.execute_reply.started":"2024-06-16T10:26:55.602846Z","shell.execute_reply":"2024-06-16T10:26:55.624158Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Dataset Information","metadata":{}},{"cell_type":"code","source":"spam_df.info()","metadata":{"execution":{"iopub.status.busy":"2024-06-16T10:26:58.722141Z","iopub.execute_input":"2024-06-16T10:26:58.722622Z","iopub.status.idle":"2024-06-16T10:26:58.750702Z","shell.execute_reply.started":"2024-06-16T10:26:58.722587Z","shell.execute_reply":"2024-06-16T10:26:58.749141Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Statistical Analysis","metadata":{}},{"cell_type":"code","source":"spam_df.describe().T","metadata":{"execution":{"iopub.status.busy":"2024-06-16T10:27:01.962955Z","iopub.execute_input":"2024-06-16T10:27:01.964083Z","iopub.status.idle":"2024-06-16T10:27:01.987785Z","shell.execute_reply.started":"2024-06-16T10:27:01.964007Z","shell.execute_reply":"2024-06-16T10:27:01.986506Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"spam_df.dtypes","metadata":{"execution":{"iopub.status.busy":"2024-06-16T10:27:04.682324Z","iopub.execute_input":"2024-06-16T10:27:04.682765Z","iopub.status.idle":"2024-06-16T10:27:04.691479Z","shell.execute_reply.started":"2024-06-16T10:27:04.682733Z","shell.execute_reply":"2024-06-16T10:27:04.690263Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(spam_df['text'].unique())","metadata":{"execution":{"iopub.status.busy":"2024-06-16T10:27:07.187132Z","iopub.execute_input":"2024-06-16T10:27:07.187558Z","iopub.status.idle":"2024-06-16T10:27:07.216775Z","shell.execute_reply.started":"2024-06-16T10:27:07.187528Z","shell.execute_reply":"2024-06-16T10:27:07.215572Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 2. Data Cleaning","metadata":{}},{"cell_type":"markdown","source":"## Missing Values","metadata":{}},{"cell_type":"code","source":"#Check Null values\nspam_df.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2024-06-16T10:27:10.050945Z","iopub.execute_input":"2024-06-16T10:27:10.051381Z","iopub.status.idle":"2024-06-16T10:27:10.061782Z","shell.execute_reply.started":"2024-06-16T10:27:10.051348Z","shell.execute_reply":"2024-06-16T10:27:10.060658Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#To check if there are any missing values\nis_any_missing_data=spam_df.isna().any().any()\nis_any_missing_data","metadata":{"execution":{"iopub.status.busy":"2024-06-16T10:27:46.015691Z","iopub.execute_input":"2024-06-16T10:27:46.016211Z","iopub.status.idle":"2024-06-16T10:27:46.028675Z","shell.execute_reply.started":"2024-06-16T10:27:46.016174Z","shell.execute_reply":"2024-06-16T10:27:46.027214Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**No Missing Values**","metadata":{}},{"cell_type":"markdown","source":"## Duplicate Values","metadata":{}},{"cell_type":"code","source":"spam_df.duplicated().sum()","metadata":{"execution":{"iopub.status.busy":"2024-06-16T10:27:53.375702Z","iopub.execute_input":"2024-06-16T10:27:53.376111Z","iopub.status.idle":"2024-06-16T10:27:53.407911Z","shell.execute_reply.started":"2024-06-16T10:27:53.37608Z","shell.execute_reply":"2024-06-16T10:27:53.406623Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**There are 33 duplicated values that has to be removed**","metadata":{}},{"cell_type":"code","source":"#Fetch all duplicate values\nduplicate=spam_df[spam_df.duplicated(keep='last')]\nduplicate.head()","metadata":{"execution":{"iopub.status.busy":"2024-06-16T10:27:56.446771Z","iopub.execute_input":"2024-06-16T10:27:56.447206Z","iopub.status.idle":"2024-06-16T10:27:56.484515Z","shell.execute_reply.started":"2024-06-16T10:27:56.447173Z","shell.execute_reply":"2024-06-16T10:27:56.483101Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Remove Duplicate Records\nspam_df.drop_duplicates(inplace=True)\nspam_df.duplicated().sum()","metadata":{"execution":{"iopub.status.busy":"2024-06-16T10:28:02.459239Z","iopub.execute_input":"2024-06-16T10:28:02.459658Z","iopub.status.idle":"2024-06-16T10:28:02.516455Z","shell.execute_reply.started":"2024-06-16T10:28:02.459629Z","shell.execute_reply":"2024-06-16T10:28:02.515064Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 3. Data Preprocessing","metadata":{}},{"cell_type":"markdown","source":"**Rename Column names**","metadata":{}},{"cell_type":"code","source":"# Rename names columns\nspam_df=spam_df.rename(columns={'spam':'label'})","metadata":{"execution":{"iopub.status.busy":"2024-06-16T10:28:59.529242Z","iopub.execute_input":"2024-06-16T10:28:59.5297Z","iopub.status.idle":"2024-06-16T10:28:59.536309Z","shell.execute_reply.started":"2024-06-16T10:28:59.52967Z","shell.execute_reply":"2024-06-16T10:28:59.535337Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"spam_df[\"length\"] = spam_df[\"text\"].apply(len)\nspam_df.sort_values(by='length', ascending=False).head(3)","metadata":{"execution":{"iopub.status.busy":"2024-06-16T10:29:02.963664Z","iopub.execute_input":"2024-06-16T10:29:02.964145Z","iopub.status.idle":"2024-06-16T10:29:02.987146Z","shell.execute_reply.started":"2024-06-16T10:29:02.964054Z","shell.execute_reply":"2024-06-16T10:29:02.985808Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Distribution of Spam and Ham Emails","metadata":{}},{"cell_type":"code","source":"import plotly.express as px\n\n# Get value counts and reset the index\ncounts = spam_df['label'].value_counts().reset_index()\ncounts.columns = ['Label', 'Count']\n\n# Create a bar plot using Plotly Express with default color settings\nfig = px.bar(counts, x='Label', y='Count', color='Label', color_discrete_sequence=px.colors.qualitative.Plotly)\n\n# Update layout for title and axis titles\nfig.update_layout(title='Number of Spam and Legitimate Emails', xaxis_title='Label', yaxis_title='Count')\n\n# Update x-axis for tick values and text\nfig.update_xaxes(tickvals=[0, 1], ticktext=['Legitimate', 'Spam'])\n\n# Show the figure\nfig.show()\n","metadata":{"execution":{"iopub.status.busy":"2024-06-16T10:34:03.696558Z","iopub.execute_input":"2024-06-16T10:34:03.696977Z","iopub.status.idle":"2024-06-16T10:34:03.78562Z","shell.execute_reply.started":"2024-06-16T10:34:03.696942Z","shell.execute_reply":"2024-06-16T10:34:03.784398Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"spam_df.hist(column = 'length', by ='label',figsize=(12,4), bins = 10,color='blue')","metadata":{"execution":{"iopub.status.busy":"2024-06-16T10:34:18.613721Z","iopub.execute_input":"2024-06-16T10:34:18.615008Z","iopub.status.idle":"2024-06-16T10:34:19.213909Z","shell.execute_reply.started":"2024-06-16T10:34:18.614952Z","shell.execute_reply":"2024-06-16T10:34:19.212497Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Further Processing\n\n* **Remove Punctuations:** Strip out punctuation marks from the text to focus on the words themselves.\n* **Lowering the Case:** Convert all text to lowercase to ensure uniformity and improve matching.\n* **Remove Stop Words:** Eliminate common, non-informative words (e.g., \"and\", \"the\") that don't contribute to the analysis.\n* **Lemmatization:** Reduce words to their base or root form (e.g., \"running\" to \"run\") for better consistency.\n* **Identify Spam and Legit Words Using N-Gram Model:** Use N-grams (sequences of N words) to detect patterns and frequently occurring word combinations in spam and legitimate (ham) emails.","metadata":{}},{"cell_type":"code","source":"!unzip /usr/share/nltk_data/corpora/wordnet.zip -d /usr/share/nltk_data/corpora/","metadata":{"execution":{"iopub.status.busy":"2024-06-16T10:34:26.461602Z","iopub.execute_input":"2024-06-16T10:34:26.462021Z","iopub.status.idle":"2024-06-16T10:34:27.925699Z","shell.execute_reply.started":"2024-06-16T10:34:26.46199Z","shell.execute_reply":"2024-06-16T10:34:27.923879Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def preprocess_text(text):\n    # Remove punctuation\n    no_punctuation = ''.join([char for char in text if char not in string.punctuation])\n\n    # Lowercase the text\n    no_punctuation_lower = no_punctuation.lower()\n\n    # Tokenize the text into words\n    words = nltk.word_tokenize(no_punctuation_lower)\n\n    # Remove stopwords and non-alphabetic characters, and lemmatize\n    lemmatizer = WordNetLemmatizer()\n    lemmatized_words = [lemmatizer.lemmatize(word) for word in words if word.lower() not in stopwords.words('english') and word.isalpha()]\n\n    # Join the lemmatized words back into a sentence\n    lemmatized_text = ' '.join(lemmatized_words)\n\n    return lemmatized_text\n","metadata":{"execution":{"iopub.status.busy":"2024-06-16T10:36:54.608697Z","iopub.execute_input":"2024-06-16T10:36:54.609233Z","iopub.status.idle":"2024-06-16T10:36:54.618707Z","shell.execute_reply.started":"2024-06-16T10:36:54.609192Z","shell.execute_reply":"2024-06-16T10:36:54.61736Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"spam_df[\"preprocessed_text\"] = spam_df[\"text\"].apply(preprocess_text)\nspam_df.head()","metadata":{"execution":{"iopub.status.busy":"2024-06-16T10:36:59.647959Z","iopub.execute_input":"2024-06-16T10:36:59.648416Z","iopub.status.idle":"2024-06-16T10:40:43.981211Z","shell.execute_reply.started":"2024-06-16T10:36:59.648381Z","shell.execute_reply":"2024-06-16T10:40:43.979792Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## N-gram Plot","metadata":{}},{"cell_type":"markdown","source":"Let's define a function `plot_ngrams` visualize the most frequent N-grams (sequences of N words) in a given set of texts. It then applies this function to spam and non-spam messages from a dataset to compare their top bigrams (N-grams of size 2).\n\n### Function: `plot_ngrams`\n1. **Initialize Count Vectorizer**: Sets up a count vectorizer to extract N-grams from the texts.\n2. **Fit and Transform Texts**: Converts the texts into a matrix of N-gram counts.\n3. **Get Feature Names**: Retrieves the N-gram feature names.\n4. **Sum N-gram Occurrences**: Totals the occurrences of each N-gram.\n5. **Create N-gram Dictionary**: Maps N-grams to their counts.\n6. **Sort N-grams**: Orders the N-grams by frequency in descending order.\n7. **Select Top N-grams**: Chooses the top N N-grams based on their counts.\n8. **Plot N-grams**: Plots the top N-grams using Seaborn's barplot.\n\n### Visualization\n1. **Filter Messages**: Separates spam and non-spam messages.\n2. **Create Subplots**: Sets up side-by-side plots.\n3. **Plot Top Bigrams**: Uses `plot_ngrams` to visualize the top bigrams in spam and non-spam messages.\n4. **Display Plots**: Adjusts layout and displays the plots.\n","metadata":{}},{"cell_type":"code","source":"def plot_ngrams(ax, texts, ngram_range=(2, 2), num_top_ngrams=25, title=''):\n    # Initialize count vectorizer\n    vectorizer = CountVectorizer(ngram_range=ngram_range)\n    \n    # Fit and transform the texts\n    X = vectorizer.fit_transform(texts)\n    \n    # Get feature names\n    feature_names = vectorizer.get_feature_names_out()\n    \n    # Sum the occurrences of each n-gram\n    ngram_counts = X.sum(axis=0).A1\n    \n    # Create a dictionary of n-grams and their counts\n    ngram_dict = dict(zip(feature_names, ngram_counts))\n    \n    # Sort the dictionary by counts in descending order\n    sorted_ngrams = sorted(ngram_dict.items(), key=lambda x: x[1], reverse=True)\n    \n    # Select top N n-grams\n    top_ngrams = sorted_ngrams[:num_top_ngrams]\n    \n    # Plot the top N n-grams\n    sns.barplot(ax=ax, x=[ngram[1] for ngram in top_ngrams],\n                y=[ngram[0] for ngram in top_ngrams],\n                orient=\"h\",\n                width=0.5,\n                palette='Spectral')\n    ax.set_xlabel('Frequency')\n    ax.set_ylabel('N-gram')\n    ax.set_title(title)","metadata":{"execution":{"iopub.status.busy":"2024-06-16T10:40:44.602758Z","iopub.execute_input":"2024-06-16T10:40:44.603175Z","iopub.status.idle":"2024-06-16T10:40:44.613924Z","shell.execute_reply.started":"2024-06-16T10:40:44.603144Z","shell.execute_reply":"2024-06-16T10:40:44.612525Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Filter spam and non-spam messages\nspam_texts = spam_df[spam_df['label'] == 1]['preprocessed_text']\nnon_spam_texts = spam_df[spam_df['label'] == 0]['preprocessed_text']\n\n#Visualization\nfig, axes = plt.subplots(1, 2, figsize=(14, 6))\nplot_ngrams(axes[0], spam_texts, title='Top Bigrams in Spam Messages')\nplot_ngrams(axes[1], non_spam_texts, title='Top Bigrams in Non-Spam Messages')\naxes[0].grid(axis='x')\naxes[1].grid(axis='x')\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-06-16T10:42:20.266648Z","iopub.execute_input":"2024-06-16T10:42:20.267089Z","iopub.status.idle":"2024-06-16T10:42:25.198043Z","shell.execute_reply.started":"2024-06-16T10:42:20.267058Z","shell.execute_reply":"2024-06-16T10:42:25.196668Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 4. Feature Engineering","metadata":{}},{"cell_type":"markdown","source":"### 1. Count Vectorizer\nTransforms text data into a matrix of token (word) counts. Each entry in the matrix represents the frequency of a word in a specific document, providing a straightforward numerical representation of the text suitable for machine learning models.","metadata":{}},{"cell_type":"code","source":"# Initialize count vectorizer\nvectorizer = CountVectorizer()\n\n# Bag of words\nbow_text = vectorizer.fit_transform(spam_df[\"preprocessed_text\"])\n\n# Fetch the vocabulary set\nprint(f\"10 Bag Of Words Features: {vectorizer.get_feature_names_out()[100:110]}\")\nprint(f\"Total number of vocab words: {len(vectorizer.vocabulary_)}\")","metadata":{"execution":{"iopub.status.busy":"2024-06-16T10:45:04.235596Z","iopub.execute_input":"2024-06-16T10:45:04.236058Z","iopub.status.idle":"2024-06-16T10:45:05.330733Z","shell.execute_reply.started":"2024-06-16T10:45:04.236026Z","shell.execute_reply":"2024-06-16T10:45:05.329356Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Convert strings to vectors using BoW\ntransformed_bow = vectorizer.transform(spam_df[\"preprocessed_text\"])\n\n# Print the shape of the sparse matrix and count the number of non-zero occurrences\nprint(f\"Shape of sparse matrix: {transformed_bow.shape}\")\nprint(f\"Amount of non-zero occurrences: {transformed_bow.nnz}\")","metadata":{"execution":{"iopub.status.busy":"2024-06-16T10:45:11.037081Z","iopub.execute_input":"2024-06-16T10:45:11.037541Z","iopub.status.idle":"2024-06-16T10:45:12.014062Z","shell.execute_reply.started":"2024-06-16T10:45:11.037507Z","shell.execute_reply":"2024-06-16T10:45:12.012677Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 2. TF-IDF Vectorizer (Term Frequency-Inverse Document Frequency)\nConverts text data into a matrix where each entry reflects the importance of a word in a document relative to the entire corpus. This is calculated by multiplying term frequency (how often a word appears in a document) by inverse document frequency (how common or rare a word is across all documents). This technique helps emphasize unique words and diminish the influence of commonly occurring terms, improving model performance by highlighting significant features.","metadata":{}},{"cell_type":"code","source":"# TF-IDF\ntfidf_transformer = TfidfTransformer().fit(transformed_bow)\n\n# Transform entire BoW into tf-idf corpus\ntext_tfidf = tfidf_transformer.transform(transformed_bow)\nprint(text_tfidf.shape)","metadata":{"execution":{"iopub.status.busy":"2024-06-16T10:45:23.164457Z","iopub.execute_input":"2024-06-16T10:45:23.164917Z","iopub.status.idle":"2024-06-16T10:45:23.217137Z","shell.execute_reply.started":"2024-06-16T10:45:23.164884Z","shell.execute_reply":"2024-06-16T10:45:23.215934Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 5. Model Building","metadata":{}},{"cell_type":"markdown","source":"In this notebook, I am gonna use the following classification models\n\n1. **Support Vector Machine**\n2. **Random Forest**\n3. **Decision Tree**\n4. **Naive Bayas**\n5. **XBoost Classifier**","metadata":{}},{"cell_type":"markdown","source":"## Split the dataset into traning and testing set","metadata":{}},{"cell_type":"code","source":"# Split the dataset to train and test sets\nx_train, x_test, y_train, y_test = train_test_split(\n    text_tfidf, spam_df[\"label\"], test_size=0.2\n)\n\nprint(f\"train dataset features size: {x_train.shape}\")\nprint(f\"train dataset label size: {y_train.shape}\")\n\nprint(f\"test dataset features size: {x_test.shape}\")\nprint(f\"test dataset label size: {y_test.shape}\")","metadata":{"execution":{"iopub.status.busy":"2024-06-16T10:54:13.432716Z","iopub.execute_input":"2024-06-16T10:54:13.433184Z","iopub.status.idle":"2024-06-16T10:54:13.447801Z","shell.execute_reply.started":"2024-06-16T10:54:13.43315Z","shell.execute_reply":"2024-06-16T10:54:13.446367Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Define the Model - with Metrics, Classification Report, Confusion Matrix Visualization\n\nLet's define the `evaluate_model` function to assesses the performance of a given machine learning model on test data, calculating and printing various metrics. Here's a detailed breakdown:\n\n### Function: `evaluate_model`\n1. **Predict Labels**: Uses the model to predict labels for the test data (`x_test`).\n2. **Confusion Matrix**: Computes the confusion matrix to derive true positives (TP), true negatives (TN), false positives (FP), and false negatives (FN).\n3. **Performance Metrics**:\n    - **Accuracy**: Proportion of correct predictions.\n    - **Recall**: Proportion of actual positives correctly identified.\n    - **Precision**: Proportion of positive predictions that are correct.\n    - **F1-score**: Harmonic mean of precision and recall.\n    - **Specificity**: Proportion of actual negatives correctly identified.\n    - **Miss Rate**: Proportion of actual positives incorrectly identified as negatives.\n    - **Mean Accuracy**: Average accuracy from cross-validation.\n    - **Mean Square Error (MSE)**: Included but not applicable for classification tasks.\n4. **Classification Report**: Generates a detailed report with precision, recall, and F1-score for each class.\n5. **Print Metrics**: Displays the metrics and confusion matrix in a formatted output.\n6. **Plot Confusion Matrix**: Visualizes the confusion matrix using `ConfusionMatrixDisplay`.\n","metadata":{}},{"cell_type":"code","source":"def evaluate_model(model, x_test, y_test, model_name=\"Model\"):\n\n    # Predict labels on testing data\n    y_pred = model.predict(x_test)\n\n    # Calculate confusion matrix\n    conf_matrix = confusion_matrix(y_test, y_pred)\n\n    # Extract TP, TN, FP, FN\n    TN, FP, FN, TP = conf_matrix.ravel()\n\n    # Calculate various performance metrics\n    accuracy = accuracy_score(y_test, y_pred)\n    recall = recall_score(y_test, y_pred)\n    precision = precision_score(y_test, y_pred)\n    f1 = f1_score(y_test, y_pred)\n    specificity = TN / (TN + FP)\n    miss_rate = FN / (FN + TP)\n\n    # Calculate mean accuracy using cross-validation\n    mean_accuracy = cross_val_predict(model, x_train, y_train, cv=10).mean()\n\n    # Calculate mean square error (for regression tasks, not applicable here)\n    mse = mean_squared_error(y_test, y_pred)\n    classification_rep = classification_report(y_test, y_pred, output_dict=True)\n    metrics = {\n        \"Accuracy\": accuracy,\n        \"Recall\": recall,\n        \"Precision\": precision,\n        \"F1-score\": f1,\n        \"Specificity\": specificity,\n        \"Miss Rate\": miss_rate,\n        \"Mean Accuracy\": mean_accuracy,\n        \"Mean Square Error\": mse,\n        \"Classification Report\": classification_rep\n    }\n    # Print evaluation metrics\n    print(f\"\\033[1m EVALUATION METRICS ({model_name}) \\033[0m\")\n    print(f\"\\n \\033 ---------------------------------------------------------------- \\033[0m\")\n    print(\"\\nTrue Positives (TP):\", TP)\n    print(\"True Negatives (TN):\", TN)\n    print(\"False Positives (FP):\", FP)\n    print(\"False Negatives (FN):\", FN)\n    print(\"\\nAccuracy   : \", accuracy)\n    print(\"Recall       : \", recall)\n    print(\"Precision    : \", precision)\n    print(\"F1-score     : \", f1)\n    print(\"Specificity  : \", specificity)\n    print(\"Miss Rate    : \", miss_rate)\n    print(\"Mean Accuracy: \", mean_accuracy)\n    print(\"Mean Square Error:\", mse)  # Not applicable for classification\n    print(f\" \\033 ---------------------------------------------------------------- \\033[0m\")\n\n    # Print classification report\n    print(\"\\033[1m Classification Report: \\033[0m\")\n    print(classification_report(y_test, y_pred))\n    print(f\"\\n \\033 ---------------------------------------------------------------- \\033[0m\")\n    print(\"\\033[1m Confusion Matrix \\033[0m\")\n    # Plot the confusion matrix\n    disp = ConfusionMatrixDisplay(confusion_matrix=conf_matrix)\n    disp.plot(cmap='bone_r')  # specify the colormap for better visualization\n    plt.show()\n    return metrics,y_pred","metadata":{"execution":{"iopub.status.busy":"2024-06-16T11:05:38.94972Z","iopub.execute_input":"2024-06-16T11:05:38.950153Z","iopub.status.idle":"2024-06-16T11:05:38.965482Z","shell.execute_reply.started":"2024-06-16T11:05:38.950118Z","shell.execute_reply":"2024-06-16T11:05:38.964137Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 1. Support Vector Machine (SVM)\nA powerful classification algorithm that finds the optimal hyperplane separating different classes by maximizing the margin between them. SVM is effective in high-dimensional spaces and is used for its accuracy and efficiency in text classification tasks.\n","metadata":{}},{"cell_type":"code","source":"# Train SVM model\nsvm_model = SVC()\nsvm_model.fit(x_train, y_train)\n\n# Evaluate SVM model\nsvm_metrics,y_pred_svm = evaluate_model(svm_model, x_test, y_test, model_name=\"SVM\")","metadata":{"execution":{"iopub.status.busy":"2024-06-16T11:05:42.589683Z","iopub.execute_input":"2024-06-16T11:05:42.590126Z","iopub.status.idle":"2024-06-16T11:07:02.826082Z","shell.execute_reply.started":"2024-06-16T11:05:42.59009Z","shell.execute_reply":"2024-06-16T11:07:02.824647Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 2. Random Forest\nAn ensemble learning method that constructs multiple decision trees during training and outputs the mode of their predictions for classification. It improves accuracy and robustness by reducing overfitting and variance, making it well-suited for handling large datasets with complex patterns.","metadata":{}},{"cell_type":"code","source":"# Train Random Forest model\nrandomForest_model = RandomForestClassifier()\nrandomForest_model.fit(x_train, y_train)\n\n# Evaluate Random Forest model\nrf_metrics,y_pred_rf = evaluate_model(randomForest_model, x_test, y_test, model_name=\"Random Forest\")","metadata":{"execution":{"iopub.status.busy":"2024-06-16T11:00:33.937964Z","iopub.execute_input":"2024-06-16T11:00:33.938922Z","iopub.status.idle":"2024-06-16T11:01:23.219882Z","shell.execute_reply.started":"2024-06-16T11:00:33.938882Z","shell.execute_reply":"2024-06-16T11:01:23.218493Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 3. Decision Tree\nA tree-structured model where nodes represent feature decisions, and branches represent outcomes, leading to a final decision at the leaf nodes. Decision Trees are easy to interpret and visualize but can be prone to overfitting if not properly pruned.","metadata":{}},{"cell_type":"code","source":"# Train Decision Tree Model\ndecisionTree_model = DecisionTreeClassifier()\ndecisionTree_model.fit(x_train, y_train)\n\n# Evaluate\ndt_metrics,y_pred_dt = evaluate_model(decisionTree_model, x_test, y_test, model_name=\"Decision Tree\")","metadata":{"execution":{"iopub.status.busy":"2024-06-16T11:01:29.469597Z","iopub.execute_input":"2024-06-16T11:01:29.470521Z","iopub.status.idle":"2024-06-16T11:01:39.623354Z","shell.execute_reply.started":"2024-06-16T11:01:29.470484Z","shell.execute_reply":"2024-06-16T11:01:39.622002Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 4. Naive Bayes\nA probabilistic classifier based on Bayes' theorem with an assumption of independence between features. It is highly efficient and works particularly well for text classification, such as spam detection, due to its simplicity and effectiveness in handling large vocabularies.","metadata":{}},{"cell_type":"code","source":"# Define Naive Bayas model\nNaiveBayes_model = GaussianNB()\nNaiveBayes_model.fit(x_train.toarray(), y_train)\n\n# Evaluate\nnb_metrics,y_pred_nb = evaluate_model(decisionTree_model, x_test.toarray(), y_test, model_name=\"Naive Bayes\")","metadata":{"execution":{"iopub.status.busy":"2024-06-16T11:01:46.030293Z","iopub.execute_input":"2024-06-16T11:01:46.031169Z","iopub.status.idle":"2024-06-16T11:01:58.811679Z","shell.execute_reply.started":"2024-06-16T11:01:46.031124Z","shell.execute_reply":"2024-06-16T11:01:58.810294Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 5. XGBoost Classifier\nAn optimized gradient boosting algorithm designed for speed and performance. XGBoost builds an ensemble of weak learners (typically decision trees) in a sequential manner, focusing on reducing errors from previous iterations. It is known for its high accuracy and scalability in various classification tasks.","metadata":{}},{"cell_type":"code","source":"# Create the XGBoost model\nxgboost_model = XGBClassifier(\n    max_depth=3,\n    learning_rate=0.1,\n    n_estimators=100,\n    objective='binary:logistic',  # Use 'multi:softmax' for multi-class classification\n    eval_metric='logloss'\n)\n\n# Fit the model to the training data\nxgboost_model.fit(x_train, y_train)\n\n# Predict using the trained model\n#y_pred_xgb = xgboost_model.predict(x_test)\n\n# Evaluate the model\nxgb_metrics, y_pred_xgb = evaluate_model(xgboost_model, x_test, y_test, model_name=\"XGBoost\")\n","metadata":{"execution":{"iopub.status.busy":"2024-06-16T11:02:12.922462Z","iopub.execute_input":"2024-06-16T11:02:12.922862Z","iopub.status.idle":"2024-06-16T11:03:09.428642Z","shell.execute_reply.started":"2024-06-16T11:02:12.922833Z","shell.execute_reply":"2024-06-16T11:03:09.427357Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Model Comparision","metadata":{}},{"cell_type":"code","source":"svm_fpr, svm_tpr, threshold = roc_curve(y_test, y_pred_svm)\nauc_svm = auc(svm_fpr, svm_tpr)\nrf_fpr, rf_tpr, threshold = roc_curve(y_test, y_pred_rf)\nauc_rfc = auc(rf_fpr, rf_tpr)\ndt_fpr, dt_tpr, threshold = roc_curve(y_test, y_pred_dt)\nauc_rfc = auc(dt_fpr, dt_tpr)\nnb_fpr, nb_tpr, threshold = roc_curve(y_test, y_pred_nb)\nauc_rfc = auc(nb_fpr, nb_tpr)\nxgb_fpr, xgb_tpr, threshold = roc_curve(y_test, y_pred_xgb)\nauc_xgb = auc(xgb_fpr, xgb_tpr)","metadata":{"execution":{"iopub.status.busy":"2024-06-16T11:07:30.641254Z","iopub.execute_input":"2024-06-16T11:07:30.641673Z","iopub.status.idle":"2024-06-16T11:07:30.657589Z","shell.execute_reply.started":"2024-06-16T11:07:30.641643Z","shell.execute_reply":"2024-06-16T11:07:30.656261Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## ROC and AUC Visualization","metadata":{}},{"cell_type":"code","source":"classifiers = {\n    'Naive Bayes': (y_pred_nb, nb_fpr, nb_tpr),\n    'Decision Tree Classifier': (y_pred_dt, dt_fpr, dt_tpr),\n    'SVM': (y_pred_svm, svm_fpr, svm_tpr),\n    'RandomForest Classifier': (y_pred_rf, rf_fpr, rf_tpr),\n    'XGBoost Classifier': (y_pred_xgb, xgb_fpr, xgb_tpr)\n}\n\nplt.figure(figsize=(8, 6), dpi=100)\ncolors=['crimson','orange','steelblue','limegreen', 'red']\n\n\nfor i, (clf_name, (y_pred, fpr, tpr)) in enumerate(classifiers.items()):\n    auc_score = roc_auc_score(y_test, y_pred)  # Calculate AUC score using roc_auc_score\n    sns.lineplot(x=fpr, y=tpr, marker='.', label=f'{clf_name} (AUC = {auc_score:.3f})', color=colors[i])\n\n# Loop through classifiers and plot ROC curves\n#for clf_name, (y_pred, fpr, tpr) in classifiers.items():\n#    auc_score = roc_auc_score(y_test, y_pred)  # Calculate AUC score using roc_auc_score\n#    sns.lineplot(x=fpr, y=tpr, marker='.', label=f'{clf_name} (AUC = {auc_score:.3f})')  # Use seaborn lineplot\n\n# plot\nplt.xlabel('False Positive Rate (FPR)')\nplt.ylabel('True Positive Rate (TPR)')\nplt.title('ROC Curves for Classifiers')\nplt.grid(True)\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-06-16T11:07:34.080452Z","iopub.execute_input":"2024-06-16T11:07:34.080872Z","iopub.status.idle":"2024-06-16T11:07:34.591429Z","shell.execute_reply.started":"2024-06-16T11:07:34.080839Z","shell.execute_reply":"2024-06-16T11:07:34.590155Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Extract metric names and values\nmetric_names = list(svm_metrics.keys())\nsvm_values = [svm_metrics[key] for key in metric_names if key != 'Classification Report']\nrf_values = [rf_metrics[key] for key in metric_names if key != 'Classification Report']\ndt_values = [dt_metrics[key] for key in metric_names if key != 'Classification Report']\nnb_values = [nb_metrics[key] for key in metric_names if key != 'Classification Report']\nxgb_values = [xgb_metrics[key] for key in metric_names if key != 'Classification Report']\n\nlength = len(metric_names)-1\n\nlength_svm = len(svm_values)\nlength_rf = len(rf_values)\nlength_dt = len(dt_values)\nlength_nb = len(nb_values)\nlength_xgb = len(xgb_values)\n\nprint(length,length_svm,length_rf,length_dt,length_nb, length_xgb)\nprint()","metadata":{"execution":{"iopub.status.busy":"2024-06-16T11:07:49.002259Z","iopub.execute_input":"2024-06-16T11:07:49.002689Z","iopub.status.idle":"2024-06-16T11:07:49.013354Z","shell.execute_reply.started":"2024-06-16T11:07:49.002657Z","shell.execute_reply":"2024-06-16T11:07:49.011969Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Bar Chart Comparision of Metrix","metadata":{}},{"cell_type":"code","source":"# Create a bar chart\nplt.figure(figsize=(10, 6))\nx = np.arange(len(metric_names) - 1)  # Assuming metric_names has the names excluding 'Classification Report'\nwidth = 0.2\n\n# Plot bars for each model with different colors\nplt.bar(x - 2*width, svm_values, width, label='SVM', color='limegreen')\nplt.bar(x - width, rf_values, width, label='Random Forest', color='gold')\nplt.bar(x, dt_values, width, label='Decision Tree', color='tomato')\nplt.bar(x + width, nb_values, width, label='Naive Bayes', color='deepskyblue')\nplt.bar(x + 2*width, xgb_values, width, label='XGBoost', color='mediumorchid')\n\nplt.xticks(x, [name for name in metric_names if name != 'Classification Report'], rotation=45, ha='right')\nplt.ylabel('Metric Score')\nplt.title('Comparison of Model Metrics')\nplt.legend()\n\n# Show the plot\nplt.grid(axis='y', linestyle='--', alpha=0.7)\nplt.tight_layout()\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2024-06-16T11:09:32.274502Z","iopub.execute_input":"2024-06-16T11:09:32.275795Z","iopub.status.idle":"2024-06-16T11:09:32.721296Z","shell.execute_reply.started":"2024-06-16T11:09:32.275745Z","shell.execute_reply":"2024-06-16T11:09:32.720189Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **|| END OF NOTEBOOK ||**","metadata":{}}]}